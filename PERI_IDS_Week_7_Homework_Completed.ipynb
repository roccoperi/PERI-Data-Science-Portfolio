{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 7 Completed: Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Data Loading and Exploration (20 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "import pandas as pd\n",
    "\n",
    "#Part 1\n",
    "#Loading the Housing Dataset \n",
    "housing = fetch_california_housing()\n",
    "\n",
    "#Pandas DataFrames for Features and Series fo rthe target variable\n",
    "X = pd.DataFrame(housing.data, columns = housing.feature_names)\n",
    "Y = pd.Series(housing.target, name='med_house_value')\n",
    "\n",
    "#First 5 Rows of Feature Variable\n",
    "print(X.head())\n",
    "\n",
    "#First 5 Rows of Target Variable\n",
    "print(Y.head())\n",
    "\n",
    "#Printing the Feature Names & Missing Values Per Column\n",
    "print(X.dtypes)\n",
    "print(X.isnull().sum())\n",
    "#Because the sum of the is null for all the features is 0, that means that there are no missing values in this data set\n",
    "\n",
    "#Summary Statistics of Features\n",
    "print(X.describe(percentiles=None, include=None, exclude=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Linear Regression on Unscaled Data (30 points)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 2\n",
    "#Splitting the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Training the linear regression model on unscaled data\n",
    "lin_reg_raw = LinearRegression()\n",
    "lin_reg_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "print('Coefficients:', lin_reg_raw.coef_)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_raw = lin_reg_raw.predict(X_test_raw)\n",
    "\n",
    "# Model Performance Metrics\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw)\n",
    "rmse_raw = root_mean_squared_error(y_test, y_pred_raw)\n",
    "r2_raw = r2_score(y_test, y_pred_raw)\n",
    "\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_raw:.2f}\")\n",
    "print(f\"R² Score: {r2_raw:.2f}\")\n",
    "\n",
    "# MSE = .56\n",
    "# RMSE = .75\n",
    "# R^2 Score = .58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation Questions\n",
    "*What does the R² score tell us about model performance?*\n",
    "\n",
    "The R² value of .58 means that 58% of the variation in the median household value is explained by the feature variables of the dataset. With this in mind, there is then 42% of unexplained variation of median household value that is not explained by the feature variables. As a starting point, a .58 R² score is not bad, as from this, we can narrow or expand upon the model to either include other feature variables that may have more impact or exclude the feature variables that were not statistically significant in the model. \n",
    "\n",
    "*Which features seem to have the strongest impact on predictions based on the model’s coefficients?*\n",
    "\n",
    "From the coefficients, it seems that the median income in the block group, the average number of bedrooms, and the latitude and longitude had strongest impact on the predictions, as the coefficients on such had larger values than some of the other feature variables. The coefficients on those variables were .448, .783, -.419, and -.433 respectively, meaning that factors such as income level, bedrooms, and location ultimately infleunce the median household value for California districts. \n",
    "\n",
    "*How well do the predicted values match the actual values?*\n",
    "\n",
    "The RMSE of the regression is .75, meaning that on average, our predicted values vary from the actual values by .75, or in terms of the units of the dataset, by $75,000. Given that California has a variety of districts that vary very drastically in income level, this RMSE is not too bad, but as always, a lower RMSE would make our predicted y more reliable/more accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Skipped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Feature Selection and Simplified Model (25 points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For my simplified model, I am choosing median household income of the district block, the average # of rooms and the average number of bedrooms as the features for my simple model. I believe that these three features capture most of the variation in Y, as the coefficients of these features in the past regression with the 5 other features were relatively strong. Also, intuitively in makes sense for these variables to impact the average median value of a home, as higher tax bracket individuals are more likely to afford higher value homes, and the more rooms/bedrooms a house has, generally the more expensive it is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Part 4: Simplified Model \n",
    "\n",
    "#Features being used, median household income, average rooms, average bedrooms\n",
    "\n",
    "#Selecting three features\n",
    "Simple_X = X[['MedInc', 'AveRooms', 'AveBedrms']]\n",
    "\n",
    "#Splitting the dataset into training and test sets\n",
    "X_train_raw_S, X_test_raw_S, y_train_S, y_test_S = train_test_split(Simple_X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Training the linear regression model on unscaled data\n",
    "lin_reg_raw_S = LinearRegression()\n",
    "lin_reg_raw_S.fit(X_train_raw_S, y_train_S)\n",
    "\n",
    "print(\"Model Coefficients (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw_S.coef_,\n",
    "                index=Simple_X.columns))\n",
    "print(\"\\nModel Intercept (Unscaled):\")\n",
    "print(pd.Series(lin_reg_raw_S.intercept_))\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_raw_S = lin_reg_raw_S.predict(X_test_raw_S)\n",
    "\n",
    "# Model Performance Metrics\n",
    "mse_raw_S = mean_squared_error(y_test_S, y_pred_raw_S)\n",
    "rmse_raw_S = root_mean_squared_error(y_test_S, y_pred_raw_S)\n",
    "r2_raw_S = r2_score(y_test_S, y_pred_raw_S)\n",
    "\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw_S:.2f}\")\n",
    "print(f\"Root Mean Squared Error: {rmse_raw_S:.2f}\")\n",
    "print(f\"R² Score: {r2_raw_S:.2f}\")\n",
    "\n",
    "# MSE = .68\n",
    "# RMSE = .82\n",
    "# R^2 Score = .48\n",
    "\n",
    "# In comparing the two different regression models, the simpler model performed worse \n",
    "# than the other model in terms of accuracy and predictability. The R^2 score in the \n",
    "# simple model was .10 lower than the R^2 score in the more complex model, meaning that 10% of the variation\n",
    "# in Y was lost when we transitions from the more complex model to the more simple model. Furthermore, the \n",
    "# RMSE increased by .07, meaning that the average difference between the actual and predicted y increased by $7,000 \n",
    "# when we switched the models, making the simpler model less accurate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation Questions\n",
    "*How does the simplified model compare to the full model?*\n",
    "\n",
    "As I explained above in the commented code, the simpler model is less reliable and less accurate than the more complex model due to the lower R^2 score and higher RMSE score.\n",
    "\n",
    "*Would you use this simplified model in practice? Why or why not?*\n",
    "\n",
    "In practice, I would use this simpler model because with less parameters(in this case, features), interpretability of the model becomes greater as there are less confounding effects from other features. Furthermore, by intitially starting out with less parameters, you have flexibility in future model creation by understanding the specific role of each of the parameters. \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
